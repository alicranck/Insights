# daily update of new files and merging to the DB. a new icu_mort.csv file should be submitted daily #
import pymongo
from pymongo import MongoClient
import cPickle as pickle
client = MongoClient()
db=client.icu_db
MEDICAL_INFO_COLUMNS_CLUSTERING = ["Arterial Pressure Diastolic (mmHg)"  , 
    "Arterial Pressure Systolic (mmHg)"   ,
            "Base excess (vt) (mmol/l)"   ,
             "Bilirubin(Total) (mg/dl)"   ,
                      "Calcium (mg/ml)"   ,
                   "Creatinine (mg/dl)"   ,
                 "End Tidal CO2 (mmHg)"   ,
                                  "GCS"   ,
                       "GastricResidue"   ,
                    "Gluco-stick (mg%)"   ,
                   "Glucose ABG (mg%)"   ,
                         "Haematocrit"   ,
                    "Heart Rate (bpm)"   ,
                 "Inspired Oxygen (%)"   ,
                "Lactate ABG (mmol/l)"   ,
                  "Magnesium (mmol/l)"   ,
                     "Na-ABG (mmol/l)"   ,
                            "PH (ABG)"   ,
                               "PaCO2"   ,
                                "PaO2"   ,
                  "Platelets (10^9/l)"   ,
                        "PotassiumABG"   ,
                 "Pre-albumin (mg/dl)"   ,
                                "SpO2"   ,
                   "Total Haemoglobin"   ,
   "Total Respiratory Rate (insp/min)"   ,
                       "Urea (mmol/l)"   ,
           "White Cell Count (10^9/l)"  ,
                    "chronic-category"   ,
                        "isVentilated"   ,
                              "sepsis"]

FEATURES_XGB=[u'Arterial Pressure Diastolic (mmHg)',
 u'Arterial Pressure Systolic (mmHg)',
 u'Base excess (vt) (mmol/l)',
 u'Bilirubin(Total) (mg/dl)',
 u'Calcium (mg/ml)',
 u'Creatinine (mg/dl)',
 u'End Tidal CO2 (mmHg)',
 u'GCS',
 u'GastricResidue',
 u'Gluco-stick (mg%)',
 u'Glucose ABG (mg%)',
 u'Haematocrit',
 u'Heart Rate (bpm)',
 u'Inspired Oxygen (%)',
 u'Lactate ABG (mmol/l)',
 u'Magnesium (mmol/l)',
 u'Na-ABG (mmol/l)',
 u'PH (ABG)',
 u'PaCO2',
 u'PaO2',
 u'Platelets (10^9/l)',
 u'PotassiumABG',
 u'Pre-albumin (mg/dl)',
 u'SpO2',
 u'Total Haemoglobin',
 u'Total Respiratory Rate (insp/min)',
 u'Urea (mmol/l)',
 u'White Cell Count (10^9/l)',
 u'age2',
 u'chronic-category',
 u'dayNum',
 u'gender2',
 u'isVentilated',
 u'\u05db\u05de\u05d5\u05ea \u05e9\u05e0\u05d9\u05ea\u05e0\u05d4 KCALENT',
 u'\u05db\u05de\u05d5\u05ea \u05e9\u05e0\u05d9\u05ea\u05e0\u05d4 KCALIV']							
							  
for filename in glob.glob(r'C:\Users\veronica\Documents\ICU data\icu_mort.csv'):
    print(filename)
    df=pd.read_csv(filename)
    if u'מספר אשפוז' in df.columns:
        df[u'מספר אשפוז']=df[u'מספר אשפוז'].apply(lambda x: hashlib.md5(str(x)).hexdigest())
    if 'MR Number' in df.columns:
        df['MR Number']=df['MR Number'].apply(lambda x: hashlib.md5(str(x)).hexdigest())
    if 'mr number' in df.columns:
        df['MR Number']=df['mr number'].apply(lambda x: hashlib.md5(str(x)).hexdigest())
    if 'ID' in df.columns:
        df['ID']=df['ID'].apply(lambda x: hashlib.md5(str(x)).hexdigest())
    if 'adm.num' in df.columns:
        df['adm.num']=df['adm.num'].apply(lambda x: hashlib.md5(str(x)).hexdigest())
    
    df=df.drop([u'שם החולה','Admission_Number (an)','name','adm.num.long'],axis=1,errors='ignore')
    print df.head(5)
    df.to_csv(r'C:\Users\veronica\Documents\ICU data\\'+filename.split("\\")[-1]+'_discreet.csv', encoding='utf-8')

# edit demographic file
df=pd.read_csv(r'C:\Users\veronica\Documents\ICU data\icu_mort_discreet.csv')
from datetime import timedelta
df['mortality.date2']=pd.to_datetime(df['mortality.date'],format="%d/%m/%Y").dt.date
df['dis.unit2']=pd.to_datetime(df['dis.unit'],format="%d/%m/%Y").dt.date
#df['diff']=df['mortality.date2']-df['dis.unit2']
def f(df):
    if (pd.isnull(df['mortality.date2']))   :
        val=0
    elif df['mortality.date2']>df['dis.unit2']:
        val=0
    else:
        val=1
    return val
df['mort.adm']=df.apply(f,axis=1)
df.to_csv(r'C:\Users\veronica\Documents\ICU data\icu_mort_edited2.csv')

# format xsl files to csvs

dfc=pd.read_csv(r'C:\Users\veronica\Documents\ICU data\icu_mort_edited2.csv')
for filename in glob.glob(r'C:\Users\veronica\Documents\ICU data\120117\*.xlsx'):
    print(filename)
    dfe= pd.read_excel(filename)
    dfe=dfe.rename(columns={u'זמן':'Time'}) #rename for convention
    dfe=dfe.rename(columns={u'זמן התחלה':'Time'})
    dfe=dfe.rename(columns={u'תאריך':'Time'})
    dfe=dfe.rename(columns={'MR Number':u'מספר אשפוז'})
    dfe['day']=dfe['Time'].dt.date
    dfe['year']=dfe['Time'].dt.year
    dfe=dfe.groupby([u'מספר אשפוז','day'], as_index=False).mean()
    dfm=pd.merge(dfe,dfc,left_on=[u'מספר אשפוז','year'], right_on=['ID','adm.year']) #inner join
    dfm2=pd.merge(dfe,dfc,left_on=[u'מספר אשפוז','year'], right_on=['adm.num','adm.year'])
    dfm3=dfm.append(dfm2)

    dfm3.to_csv(r'C:\Users\veronica\Documents\ICU data\full_csvs3\\'+filename.split("\\")[-1]+'.csv', encoding='utf-8')
	
dfc=pd.read_csv(r'C:\Users\veronica\Documents\ICU data\icu_mort_edited2.csv')
for filename in glob.glob(r'C:\Users\veronica\Documents\ICU data\120117\*.xls'):
    print(filename)
    dfe= pd.read_excel(filename)
    dfe=dfe.rename(columns={u'זמן':'Time'}) #rename for convention
    dfe=dfe.rename(columns={u'זמן התחלה':'Time'})
    dfe=dfe.rename(columns={u'תאריך':'Time'})
    dfe=dfe.rename(columns={'MR Number':u'מספר אשפוז'})
    dfe['day']=dfe['Time'].dt.date
    dfe['year']=dfe['Time'].dt.year
    dfe=dfe.groupby([u'מספר אשפוז','day'], as_index=False).mean()
    dfm=pd.merge(dfe,dfc,left_on=[u'מספר אשפוז','year'], right_on=['ID','adm.year']) #inner join
    dfm2=pd.merge(dfe,dfc,left_on=[u'מספר אשפוז','year'], right_on=['adm.num','adm.year'])
    dfm3=dfm.append(dfm2)

    dfm3.to_csv(r'C:\Users\veronica\Documents\ICU data\full_csvs3\\'+filename.split("\\")[-1]+'.csv', encoding='utf-8')
	
# create the final table
def merge_to_db(): 
	from datetime import timedelta

	df=pd.DataFrame()
	df=pd.DataFrame(list(db.all_feats_collection.find()))
	b=0
	df['adm.unit']=pd.to_datetime(df['adm.unit'])
	df['birth.date']=pd.to_datetime(df['birth.date'])
	print df['adm.unit'].dtype, df['birth.date'].dtype
	df['age2']=df['adm.unit'].dt.year - df['birth.date'].dt.year
	dfg=pd.get_dummies(df['gender'])
	df=pd.concat([df,dfg],axis=1)
	del df['birth.date'],df['M'],df['gender']
	df=df.rename(columns={'F':'gender'})
	df['day']=pd.to_datetime(df.day)
	for filename in glob.glob(r'C:\Users\veronica\Documents\ICU data\full_csvs3\*.csv'):
		print(filename)
		dft=pd.read_csv(filename,low_memory=False)
		if('Unnamed' in dft.columns):
			del dft['Unnamed']
		if('OK_Time' in dft.columns):
			del dft['OK_Time']
		
		dft=dft.drop(['Admission_Number (an)','Unnamed: 7_x','Unnamed: 0','Unnamed: 0.1','adm.unit_x',u'מספר אשפוז',u'מספר אשפוז_y','adm.unit_y','dis.unit_x','dis.unit_y','adm.unit','dis.unit','birth.date','gender'],axis=1,errors='ignore')
		df=df.drop(['Admission_Number (an)'],axis=1,errors='ignore')
		dft['day']=pd.to_datetime(dft.day)
		df=pd.merge(df, dft, left_on=['adm.num','day'], right_on=['adm.num','day'],how='outer')
		print df.shape

	df=df.rename(columns={'chronic_category':'chronic-category'})
	df=df.rename(columns={'sepsis_categorical':'sepsis-categorical'})
	df['day']=pd.to_datetime(df['day'],format="%m/%d/%Y")
	df['year']=df['day'].dt.year
	if 'Calcium (mg/ml)_x' in df.columns:
		df['Calcium (mg/ml)']=df['Calcium (mg/ml)_x']

	df=df.drop([col for col in df.columns if ('_' in col or 'ID' in col or 'mort.adm' in col or 'age' in col or 'gender' in col or 'mortality.date'in col or 'adm.unit' in col or 'adm.year' in col)],axis=1)
	dfi=pd.read_csv(r'C:\Users\veronica\Documents\ICU data\icu_mort_edited2.csv')

	df=pd.merge(df, dfi, left_on=['adm.num','year'], right_on=['adm.num','adm.year'],how='outer')

	df['isMortDay']=pd.to_datetime(df['mortality.date']).dt.date-df['day'].dt.date
	df['dayNum']=df['day'].dt.date-pd.to_datetime(df['adm.unit'],format="%d/%m/%Y").dt.date
	df.to_csv('tmp.csv')

	def makeBool(x,i):
		if not (pd.isnull(x)):
			if(x<=np.timedelta64(timedelta(days=i)) and x>=np.timedelta64(timedelta(days=0))):
				return 1
			else:
				return 0
		else:
			return 0
	def makeBool2(x):
		if not(pd.isnull(x)):
			if(x==np.timedelta64(timedelta(days=0))):
				return 1
			else:
				return 0
		else:
			return 0

	for j in range(1,21):   
		df['isIn'+str(j)+'DaysMortDay']=df['isMortDay'].apply(makeBool,i=j)

	df['isMortDay']=df['isMortDay'].map(makeBool2)
	df['adm.unit']=pd.to_datetime(df['adm.unit'])
	df['birth.date']=pd.to_datetime(df['birth.date'])

	df['age2']=df['adm.unit'].dt.year - df['birth.date'].dt.year
	dfg=pd.get_dummies(df['gender'])
	df=pd.concat([df,dfg],axis=1)
	del df['birth.date'],df['M'],df['gender'],df['ID']
	df=df.rename(columns={'F':'gender2'})

	df=df.drop([col for col in df.columns if 'Unnamed' in col],axis=1)
	df=df.drop([col for col in df.columns if 'gender_' in col],axis=1)
	df=df.drop([col for col in df.columns if 'מספר אשפוז' in col],axis=1)

	return df

df=merge_to_db()
df=cleaning(df)

def pred_gen_mort(row): ### when presenting the general mortality predictions in the website, make sure to take only those with dayNum == 1
	row=row.drop([x for x in df.columns if ('_id' in x or 'MortDay' in x or 'Unnamed' in x or 'PROTEINI' in x or 'protein' in x or 'APACHE' in x or 'sepsis-categorical' in x)],axis=1)#'APACHE' in x or
	row['chronic-category']=(row['chronic-category']>0).astype(int)
	row['sepsis-categorical']=row['sepsis-categorical'].apply(lambda x: 1 if x>=1 else 0)
	row=row.drop(['temp_adm_num','APACHE II','mort_adm'],axis=1,errors='ignore')
	model = pickle.load(open(db.models_collection.mortality_model.path,'rb'))
	return model.predict(row)
	
def pred_3days_forward_mort(row):
	row=row.drop([x for x in df.columns if ('_id' in x or 'MortDay' in x or 'Unnamed' in x or 'PROTEINI' in x or 'protein' in x or 'APACHE' in x or 'sepsis-categorical' in x)],axis=1)#'APACHE' in x or
	row['chronic-category']=(row['chronic-category']>0).astype(int)
	row['sepsis-categorical']=row['sepsis-categorical'].apply(lambda x: 1 if x>=1 else 0)
	row=row.drop(['temp_adm_num','APACHE II','mort_adm'],axis=1,errors='ignore')
	model = pickle.load(open(db.models_collection.daysForward_model.path,'rb'))
	return model.predict(row)
	
def assign_cluster(row):
	import pickle
	row=row.drop([x for x in x.columns if x not in MEDICAL_INFO_COLUMNS], axis=1, errors='ignore')
	row['chronic-category']=(row['chronic-category']>0).astype(int)
    row=row.drop([x for x in row.columns if 'MortDay' in x or 'Unnamed' in x or 'mort' in x \
                     or 'age' in x or 'gender' in x or 'PROTEIN' in x or 'KCAL' in x \
                     or 'sepsis' in x or 'APACHE' in x or 'dayNum' in x or 'adm_num' in x or '_id' in x],axis=1,errors='ignore')
    model = pickle.load(open(db.models_collection.clustering_model.path,'rb'))
	return model.predict(row)


df['mortality_prediction'] = df.transform(pred_gen_mort)
df['next3days_mortality_prediction'] = df.transform(pred_3days_forward_mort)
df['cluster'] = df.transform(assign_cluster)
db.all_feats_collection.remove()
df=df.rename(columns={"mort.adm":"mort_adm"})
db.all_feats_collection.insert_many(df.to_dict('records'))
db.all_patients_collection.remove()
db.all_patients_collection.insert_many(dfc.to_dict('records'))
